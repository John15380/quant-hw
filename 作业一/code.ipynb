{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812947da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0. 配置与基础数学函数\n",
    "# -----------------------------------------------------------------------------\n",
    "DATA_PATH = './data/'\n",
    "OUTPUT_PATH = './answer2/'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "def winsorize(series, n_std=3):\n",
    "    \"\"\"去极值: mean +/- 3std\"\"\"\n",
    "    if series.empty: return series\n",
    "    m = series.mean()\n",
    "    s = series.std()\n",
    "    return series.clip(lower=m - n_std*s, upper=m + n_std*s)\n",
    "\n",
    "def standardize(series):\n",
    "    \"\"\"Z-score标准化\"\"\"\n",
    "    if series.empty or series.std() == 0: return series\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def neutralize(factor_series, mv_series, ind_series):\n",
    "    \"\"\"\n",
    "    行业市值中性化\n",
    "    \"\"\"\n",
    "    # 1. 数据清洗\n",
    "    mv_series = pd.to_numeric(mv_series, errors='coerce')\n",
    "    factor_series = pd.to_numeric(factor_series, errors='coerce')\n",
    "    ind_series = pd.to_numeric(ind_series, errors='coerce')\n",
    "\n",
    "    df = pd.concat([factor_series, mv_series, ind_series], axis=1)\n",
    "    df.columns = ['y', 'mv', 'ind']\n",
    "    df = df.dropna()\n",
    "    df = df[df['mv'] > 0] # 剔除市值<=0\n",
    "    \n",
    "    if df.empty: return factor_series * np.nan\n",
    "    \n",
    "    # 2. 市值处理\n",
    "    try:\n",
    "        df['log_mv'] = np.log(df['mv'])\n",
    "        df['log_mv'] = winsorize(df['log_mv'])\n",
    "        df['log_mv'] = standardize(df['log_mv'])\n",
    "    except Exception:\n",
    "        return factor_series * np.nan\n",
    "        \n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if df.empty: return factor_series * np.nan\n",
    "\n",
    "    # 3. 行业处理\n",
    "    df['ind'] = df['ind'].astype(int)\n",
    "    dummies = pd.get_dummies(df['ind'], prefix='ind', dtype=int)\n",
    "    target_cols = [f'ind_{i}' for i in range(1, 30)]\n",
    "    valid_cols = [c for c in target_cols if c in dummies.columns]\n",
    "    \n",
    "    # 4. 回归\n",
    "    if valid_cols:\n",
    "        X = pd.concat([df['log_mv'], dummies[valid_cols]], axis=1)\n",
    "    else:\n",
    "        X = df[['log_mv']]\n",
    "        \n",
    "    X = sm.add_constant(X)\n",
    "    y = df['y']\n",
    "    \n",
    "    try:\n",
    "        X = X.astype(float)\n",
    "        y = y.astype(float)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        return model.resid.reindex(factor_series.index)\n",
    "    except Exception:\n",
    "        return factor_series * np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "339b3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块一：股票池筛选\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_stock_pool(t_date, trading_days, ipo_date_series, delist_date_series, amt_df, all_columns):\n",
    "    \"\"\"\n",
    "    筛选特定日期的股票池：\n",
    "    1. 上市满252天\n",
    "    2. 未退市\n",
    "    3. 当日非停牌 (成交额>0)\n",
    "    \"\"\"\n",
    "    # 1. 上市满 252 天\n",
    "    current_idx = trading_days.searchsorted(t_date, side='right') - 1\n",
    "    cutoff_idx = current_idx - 252\n",
    "    cutoff_date = trading_days.iloc[cutoff_idx] if cutoff_idx >= 0 else pd.Timestamp.min\n",
    "    valid_ipo = ipo_date_series[ipo_date_series <= cutoff_date].index\n",
    "\n",
    "    # 2. 未退市\n",
    "    not_delisted = delist_date_series[delist_date_series.isna() | (delist_date_series > t_date)].index\n",
    "    \n",
    "    # 3. 当日非停牌\n",
    "    if t_date in amt_df.index:\n",
    "        trading_stocks = amt_df.loc[t_date][amt_df.loc[t_date] > 0].index\n",
    "    else:\n",
    "        # 容错：如果在非交易日计算，向前找最近数据\n",
    "        nearest_idx = amt_df.index.get_indexer([t_date], method='ffill')[0]\n",
    "        actual_date = amt_df.index[nearest_idx]\n",
    "        trading_stocks = amt_df.loc[actual_date][amt_df.loc[actual_date] > 0].index\n",
    "\n",
    "    # 取交集\n",
    "    pool = list(set(valid_ipo) & set(not_delisted) & set(trading_stocks))\n",
    "    # 确保在行情列名中存在\n",
    "    pool = [s for s in pool if s in all_columns]\n",
    "    \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9253a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块二：计算原始因子\n",
    "# -----------------------------------------------------------------------------\n",
    "def calculate_raw_factors(t_date, stock_pool, common_idx, \n",
    "                          close_adj, turnover, ret_daily, \n",
    "                          X_ff3_vals, Y_ret_vals, stock_codes):\n",
    "    \"\"\"\n",
    "    计算 t_date 时点的四个因子原始值\n",
    "    包含 FF3 残差的 Numpy 加速计算逻辑\n",
    "    \"\"\"\n",
    "    # 定位时间窗口 (过去21天，含当日)\n",
    "    if t_date not in common_idx:\n",
    "        loc_idx = common_idx.get_indexer([t_date], method='ffill')[0]\n",
    "    else:\n",
    "        loc_idx = common_idx.get_loc(t_date)\n",
    "        \n",
    "    # 1. 用于计算区间收益 (Return)：需要回溯 21 个间隔，即取到 t-21，总长度 22\n",
    "    start_idx = max(0, loc_idx - 21)\n",
    "    \n",
    "    # 2. 用于计算统计量 (Mean/Std/FF3)：需要最近 21 个数据点，即取到 t-20，总长度 21\n",
    "    start_idx_stat = max(0, loc_idx - 20)\n",
    "\n",
    "    end_idx = loc_idx + 1\n",
    "    \n",
    "    # 准备空结果容器\n",
    "    res = {}\n",
    "    valid_pool = [s for s in stock_pool if s in close_adj.columns]\n",
    "    \n",
    "    if not valid_pool:\n",
    "        return {k: pd.Series(dtype=float) for k in ['return_1m', 'turn_1m', 'std_1m', 'std_FF3factor_1m']}\n",
    "\n",
    "    # --- 基础因子计算 ---\n",
    "    slice_close = close_adj.iloc[start_idx : end_idx][valid_pool]\n",
    "\n",
    "    # Factor 1: return_1m\n",
    "    if len(slice_close) > 21:\n",
    "        res['return_1m'] = slice_close.iloc[-1] / slice_close.iloc[0] - 1\n",
    "    else:\n",
    "        res['return_1m'] = pd.Series(np.nan, index=valid_pool)\n",
    "\n",
    "    slice_turn = turnover.iloc[start_idx_stat : end_idx][valid_pool]\n",
    "    slice_ret = ret_daily.iloc[start_idx_stat : end_idx][valid_pool]\n",
    "    \n",
    "    # Factor 2: turn_1m\n",
    "    res['turn_1m'] = slice_turn.mean()\n",
    "\n",
    "    # Factor 3: std_1m\n",
    "    res['std_1m'] = slice_ret.std()\n",
    "\n",
    "    # --- Factor 4: std_FF3factor_1m ---\n",
    "    reg_start_idx = max(0, loc_idx - 20)\n",
    "    slice_X = X_ff3_vals[reg_start_idx:end_idx, :] # (21, 4)\n",
    "    slice_Y_all = Y_ret_vals[reg_start_idx:end_idx, :] # (21, N_all)\n",
    "    \n",
    "    # 映射股票池索引\n",
    "    pool_indices = stock_codes.get_indexer(valid_pool)\n",
    "    mask_found = pool_indices >= 0\n",
    "    pool_indices = pool_indices[mask_found]\n",
    "    valid_pool_found = np.array(valid_pool)[mask_found]\n",
    "    \n",
    "    f_ff3 = pd.Series(np.nan, index=valid_pool)\n",
    "    \n",
    "    # 仅当数据充足时计算\n",
    "    if len(slice_X) >= 15 and not np.isnan(slice_X).any() and len(pool_indices) > 0:\n",
    "        slice_Y_pool = slice_Y_all[:, pool_indices]\n",
    "        valid_cols_mask = ~np.isnan(slice_Y_pool).any(axis=0) # 剔除含NaN的列\n",
    "        \n",
    "        if np.sum(valid_cols_mask) > 0:\n",
    "            Y_clean = slice_Y_pool[:, valid_cols_mask]\n",
    "            try:\n",
    "                # 矩阵回归\n",
    "                coef, _, _, _ = np.linalg.lstsq(slice_X, Y_clean, rcond=None)\n",
    "                resid = Y_clean - slice_X @ coef\n",
    "                resid_std = np.std(resid, axis=0, ddof=1)\n",
    "                \n",
    "                # 回填数据\n",
    "                full_vals = np.full(len(valid_pool_found), np.nan)\n",
    "                full_vals[valid_cols_mask] = resid_std\n",
    "                f_ff3 = pd.Series(full_vals, index=valid_pool_found).reindex(valid_pool)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "    res['std_FF3factor_1m'] = f_ff3\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3f9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块三：因子预处理\n",
    "# -----------------------------------------------------------------------------\n",
    "def preprocess_factors(raw_factors_dict, t_date, stock_pool, \n",
    "                       share_float, close_raw, industry_code, all_stocks):\n",
    "    \"\"\"\n",
    "    对一组原始因子进行预处理：去极值 -> 中性化 -> 标准化\n",
    "    \"\"\"\n",
    "    # 准备中性化数据 (FloatMV, Ind)\n",
    "    if t_date in share_float.index and t_date in close_raw.index:\n",
    "        float_mv = share_float.loc[t_date] * close_raw.loc[t_date]\n",
    "    else:\n",
    "        float_mv = pd.Series(np.nan, index=all_stocks)\n",
    "        \n",
    "    if t_date in industry_code.index:\n",
    "        ind = industry_code.loc[t_date]\n",
    "    else:\n",
    "        ind = pd.Series(np.nan, index=all_stocks)\n",
    "        \n",
    "    proc_res = {}\n",
    "    \n",
    "    for name, s_raw in raw_factors_dict.items():\n",
    "        # 1. 仅对 Pool 内数据处理\n",
    "        s_valid = s_raw.loc[stock_pool].dropna()\n",
    "        \n",
    "        if s_valid.empty:\n",
    "            proc_res[name] = s_raw.reindex(all_stocks) # 全NaN\n",
    "            continue\n",
    "            \n",
    "        # 2. 去极值\n",
    "        s_win = winsorize(s_valid)\n",
    "        \n",
    "        # 3. 中性化\n",
    "        s_neu = neutralize(s_win, float_mv.loc[s_valid.index], ind.loc[s_valid.index])\n",
    "        \n",
    "        # 4. 标准化\n",
    "        s_std = standardize(s_neu)\n",
    "        \n",
    "        # 5. 回填至全A股列表 (非Pool为NaN)\n",
    "        proc_res[name] = s_std.reindex(all_stocks)\n",
    "        \n",
    "    return proc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3b9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块四：因子检验\n",
    "# -----------------------------------------------------------------------------\n",
    "def run_factor_test(factor_name, df_factor, close_adj, test_months, output_path):\n",
    "    \"\"\"\n",
    "    执行 RankIC 测试和分层回测，并绘图保存\n",
    "    \"\"\"\n",
    "    df_factor.index = pd.to_datetime(test_months)\n",
    "    ic_list = []\n",
    "    layer_rets = []\n",
    "    test_dates = []\n",
    "    \n",
    "    for i in range(len(test_months) - 1):\n",
    "        t_current = test_months[i]\n",
    "        t_next = test_months[i+1]\n",
    "        \n",
    "        if t_next not in close_adj.index or t_current not in close_adj.index:\n",
    "            continue\n",
    "            \n",
    "        # 计算下期收益\n",
    "        ret_next = close_adj.loc[t_next] / close_adj.loc[t_current] - 1\n",
    "        \n",
    "        try:\n",
    "            factor_val = df_factor.loc[t_current]\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "        # 对齐数据\n",
    "        df_test = pd.concat([factor_val, ret_next], axis=1).dropna()\n",
    "        df_test.columns = ['factor', 'ret']\n",
    "        if df_test.empty: continue\n",
    "            \n",
    "        # 1. RankIC\n",
    "        ic = spearmanr(df_test['factor'], df_test['ret'])[0]\n",
    "        ic_list.append(ic)\n",
    "        \n",
    "        # 2. 分层测试\n",
    "        try:\n",
    "            df_test['group'] = pd.qcut(df_test['factor'], 5, labels=False)\n",
    "            g_ret = df_test.groupby('group')['ret'].mean()\n",
    "            layer_rets.append({\n",
    "                'Layer1': g_ret.get(4, 0), # Top\n",
    "                'Layer2': g_ret.get(3, 0),\n",
    "                'Layer3': g_ret.get(2, 0),\n",
    "                'Layer4': g_ret.get(1, 0),\n",
    "                'Layer5': g_ret.get(0, 0)  # Bottom\n",
    "            })\n",
    "        except ValueError:\n",
    "            layer_rets.append({'Layer1':0,'Layer2':0,'Layer3':0,'Layer4':0,'Layer5':0})\n",
    "            \n",
    "        test_dates.append(t_current)\n",
    "        \n",
    "    # 保存结果\n",
    "    df_result = pd.concat([\n",
    "        pd.DataFrame({'RankIC': ic_list}, index=test_dates),\n",
    "        pd.DataFrame(layer_rets, index=test_dates)\n",
    "    ], axis=1)\n",
    "    \n",
    "    df_result.to_csv(os.path.join(output_path, f'factor_{factor_name}_test.csv'))\n",
    "    print(f\"Factor {factor_name} test done. Saved to CSV.\")\n",
    "    \n",
    "    # 绘图\n",
    "    try:\n",
    "        # IC\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        df_result['RankIC'].cumsum().plot(ax=ax, title=f'Cumulative RankIC - {factor_name}')\n",
    "        ax.grid(True)\n",
    "        fig.savefig(os.path.join(output_path, f'{factor_name}_cumsum_ic.png'))\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Layers\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        pd.DataFrame(layer_rets, index=test_dates).cumsum().plot(ax=ax, title=f'Returns by Layer - {factor_name}')\n",
    "        ax.grid(True)\n",
    "        fig.savefig(os.path.join(output_path, f'{factor_name}_cumsum_layers.png'))\n",
    "        plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f23e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 模块五：FF3因子日序列计算\n",
    "# -----------------------------------------------------------------------------\n",
    "def calculate_ff3_daily(close_raw, share_total, pb_lf, ret_daily):\n",
    "    \"\"\"\n",
    "    根据原始行情计算 SMB 和 HML 的日频序列 (Numpy加速版)\n",
    "    SMB: 市值后30%收益率 - 前30%收益率\n",
    "    HML: BP前30%收益率 - 后30%收益率\n",
    "    \"\"\"\n",
    "    print(\"Calculating FF3 Factors ...\")\n",
    "    \n",
    "    # 1. 对齐数据\n",
    "    # 找到所有数据的共同索引和列\n",
    "    common_idx = close_raw.index.intersection(share_total.index).intersection(pb_lf.index).intersection(ret_daily.index)\n",
    "    common_cols = close_raw.columns.intersection(share_total.columns).intersection(pb_lf.columns).intersection(ret_daily.columns)\n",
    "    \n",
    "    # 转换为 Numpy 矩阵以加速\n",
    "    mat_mv = (close_raw.loc[common_idx, common_cols] * share_total.loc[common_idx, common_cols]).values\n",
    "    mat_bp = (1 / pb_lf.loc[common_idx, common_cols]).values # BP = 1 / PB\n",
    "    mat_ret = ret_daily.loc[common_idx, common_cols].values\n",
    "    \n",
    "    n_days = len(common_idx)\n",
    "    smb_arr = np.full(n_days, np.nan)\n",
    "    hml_arr = np.full(n_days, np.nan)\n",
    "    \n",
    "    # 设置计算起点 (假设前几个月数据不稳定，从有数据处开始，这里简单全循环)\n",
    "    # 为了提速，可跳过早期空值过多的时期\n",
    "    mat_mv = (close_raw * share_total).shift(1).values \n",
    "    mat_bp = (1 / pb_lf).shift(1).values\n",
    "    mat_ret = ret_daily.values\n",
    "\n",
    "    for i in range(n_days):\n",
    "        mv_t = mat_mv[i, :]\n",
    "        bp_t = mat_bp[i, :]\n",
    "        ret_t = mat_ret[i, :]\n",
    "        \n",
    "        # 有效性掩码：三个指标都必须非NaN\n",
    "        valid_mask = (~np.isnan(mv_t)) & (~np.isnan(bp_t)) & (~np.isnan(ret_t))\n",
    "        \n",
    "        # 只要有效股票数够多才计算（例如大于50只）\n",
    "        if np.sum(valid_mask) < 50:\n",
    "            continue\n",
    "            \n",
    "        v_mv = mv_t[valid_mask]\n",
    "        v_bp = bp_t[valid_mask]\n",
    "        v_ret = ret_t[valid_mask]\n",
    "        \n",
    "        # --- 计算 SMB (按市值排序) ---\n",
    "        q30_mv = np.percentile(v_mv, 30)\n",
    "        q70_mv = np.percentile(v_mv, 70)\n",
    "        \n",
    "        small_mask = v_mv <= q30_mv\n",
    "        big_mask = v_mv >= q70_mv\n",
    "        \n",
    "        if np.any(small_mask) and np.any(big_mask):\n",
    "            # 算术平均\n",
    "            smb_val = np.mean(v_ret[small_mask]) - np.mean(v_ret[big_mask])\n",
    "            smb_arr[i] = smb_val\n",
    "            \n",
    "        # --- 计算 HML (按BP排序) ---\n",
    "        # 题目定义：HML = 前30%(High BP) - 后30%(Low BP)\n",
    "        q30_bp = np.percentile(v_bp, 30)\n",
    "        q70_bp = np.percentile(v_bp, 70)\n",
    "        \n",
    "        high_bp_mask = v_bp >= q70_bp # Top 30%\n",
    "        low_bp_mask = v_bp <= q30_bp  # Bottom 30%\n",
    "        \n",
    "        if np.any(high_bp_mask) and np.any(low_bp_mask):\n",
    "            hml_val = np.mean(v_ret[high_bp_mask]) - np.mean(v_ret[low_bp_mask])\n",
    "            hml_arr[i] = hml_val\n",
    "            \n",
    "    smb_daily = pd.Series(smb_arr, index=common_idx)\n",
    "    hml_daily = pd.Series(hml_arr, index=common_idx)\n",
    "    \n",
    "    print(\"FF3 calculation done.\")\n",
    "    return smb_daily, hml_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23fadce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Reading close_adj_day.csv...\n",
      "Reading close_day.csv...\n",
      "Reading amt_day.csv...\n",
      "Reading turn_day.csv...\n",
      "Reading share_totala_day.csv...\n",
      "Reading float_a_shares_day.csv...\n",
      "Reading cs_indus_code_day.csv...\n",
      "Reading pb_lf_day.csv...\n",
      "Reading csiall_day.csv...\n",
      "Calculating FF3 Factors ...\n",
      "FF3 calculation done.\n",
      "Starting Monthly Loop...\n",
      "Saving Factor Files...\n",
      "Running Factor Tests...\n",
      "Factor return_1m test done. Saved to CSV.\n",
      "Factor turn_1m test done. Saved to CSV.\n",
      "Factor std_1m test done. Saved to CSV.\n",
      "Factor std_FF3_1m test done. Saved to CSV.\n",
      "All Done! Results saved to: ./answer2/\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 主程序：执行全流程\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 1. 基础配置与加载\n",
    "print(\"Loading data...\")\n",
    "# 辅助函数：加载并转置，同时处理日期索引\n",
    "def load_market_data(name):\n",
    "    path = os.path.join(DATA_PATH, name)\n",
    "    print(f\"Reading {name}...\")\n",
    "    df = pd.read_csv(path, index_col=0).T\n",
    "    df.index = pd.to_datetime(df.index) # 关键：确保索引是Timestamp对象\n",
    "    return df\n",
    "\n",
    "# 加载非行情数据\n",
    "day_df = pd.read_csv(os.path.join(DATA_PATH, 'day.csv'))\n",
    "month_df = pd.read_csv(os.path.join(DATA_PATH, 'month.csv'))\n",
    "ipo_date = pd.read_csv(os.path.join(DATA_PATH, 'IPO_date_info.csv'), index_col=0)\n",
    "delist_date = pd.read_csv(os.path.join(DATA_PATH, 'delist_date_info.csv'), index_col=0)\n",
    "\n",
    "# 加载日频行情 (注意文件名后缀 _day.csv)\n",
    "close_adj = load_market_data('close_adj_day.csv')\n",
    "close_raw = load_market_data('close_day.csv')\n",
    "amt = load_market_data('amt_day.csv')\n",
    "turnover = load_market_data('turn_day.csv')\n",
    "share_total = load_market_data('share_totala_day.csv')\n",
    "share_float = load_market_data('float_a_shares_day.csv')\n",
    "industry_code = load_market_data('cs_indus_code_day.csv')\n",
    "pb_lf = load_market_data('pb_lf_day.csv')\n",
    "csi_all = load_market_data('csiall_day.csv')\n",
    "\n",
    "# 计算日收益率 (使用 fill_method=None 避免新版 pandas 警告)\n",
    "ret_daily = close_adj.pct_change(fill_method=None)\n",
    "# 假设 csi_all 第一列是指数收盘价\n",
    "mkt_daily_ret = csi_all.iloc[:, 0].pct_change(fill_method=None)\n",
    "\n",
    "# 准备日期序列\n",
    "trading_days = pd.to_datetime(day_df['date']).sort_values().reset_index(drop=True)\n",
    "month_dates = pd.to_datetime(month_df['date'])\n",
    "# 筛选回测区间: 2010-12 到 2024-11\n",
    "test_months = month_dates[(month_dates >= '2010-12-01') & (month_dates <= '2024-11-30')].tolist()\n",
    "ipo_series = pd.to_datetime(ipo_date['IPO_date'])\n",
    "delist_series = pd.to_datetime(delist_date['delist_date'])\n",
    "\n",
    "# 2. 全局计算 FF3 因子\n",
    "# 这一步计算全市场的 SMB 和 HML，用于后续个股回归\n",
    "smb_daily, hml_daily = calculate_ff3_daily(close_raw, share_total, pb_lf, ret_daily)\n",
    "\n",
    "# 构建回归所需的因子矩阵 X (Constant, Mkt, SMB, HML)\n",
    "common_idx = close_adj.index\n",
    "# 确保所有因子在时间轴上对齐\n",
    "df_ff3 = pd.DataFrame({\n",
    "    'Mkt': mkt_daily_ret,\n",
    "    'SMB': smb_daily,\n",
    "    'HML': hml_daily\n",
    "}).reindex(common_idx)\n",
    "\n",
    "# 构建 Numpy 矩阵供后续切片回归使用\n",
    "# 第一列加常数项 (Intercept)\n",
    "X_ff3_vals = np.hstack([np.ones((len(df_ff3), 1)), df_ff3.values]) \n",
    "Y_ret_vals = ret_daily.reindex(common_idx).values\n",
    "all_stocks = close_adj.columns\n",
    "\n",
    "# 3. 循环计算与处理\n",
    "print(\"Starting Monthly Loop...\")\n",
    "# 定义容器，key 名需与 calculate_raw_factors 返回的一致\n",
    "target_factors = ['return_1m', 'turn_1m', 'std_1m', 'std_FF3factor_1m']\n",
    "factors_raw_list = {k: [] for k in target_factors}\n",
    "factors_proc_list = {k: [] for k in target_factors}\n",
    "\n",
    "for t_date in test_months:\n",
    "    # date_str = t_date.strftime('%Y-%m-%d')\n",
    "    # print(f\"Processing {date_str}...\")\n",
    "    \n",
    "    # A. 股票池筛选\n",
    "    pool = get_stock_pool(t_date, trading_days, ipo_series, delist_series, amt, all_stocks)\n",
    "    \n",
    "    # B. 计算原始因子\n",
    "    raw_res = calculate_raw_factors(t_date, pool, common_idx, \n",
    "                                    close_adj, turnover, ret_daily, \n",
    "                                    X_ff3_vals, Y_ret_vals, all_stocks)\n",
    "    \n",
    "    # C. 因子预处理\n",
    "    proc_res = preprocess_factors(raw_res, t_date, pool, \n",
    "                                  share_float, close_raw, industry_code, all_stocks)\n",
    "    \n",
    "    # D. 收集结果\n",
    "    for k in target_factors:\n",
    "        # 原始值 (Reindex 确保包含所有股票，非Pool为NaN)\n",
    "        r_s = raw_res[k].reindex(all_stocks)\n",
    "        r_s.name = t_date\n",
    "        factors_raw_list[k].append(r_s)\n",
    "        \n",
    "        # 预处理值\n",
    "        p_s = proc_res[k]\n",
    "        p_s.name = t_date\n",
    "        factors_proc_list[k].append(p_s)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. 保存因子文件\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Saving Factor Files...\")\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "# 建立内部因子名到输出文件名的映射字典\n",
    "# Key: 代码中计算用的名称\n",
    "# Value: 最终保存文件的名称\n",
    "name_mapping = {\n",
    "    'return_1m': 'return_1m',\n",
    "    'turn_1m': 'turn_1m',\n",
    "    'std_1m': 'std_1m',\n",
    "    'std_FF3factor_1m': 'std_FF3_1m'  # 这里将 std_FF3factor_1m 映射为 std_FF3_1m\n",
    "}\n",
    "\n",
    "for internal_name in target_factors:\n",
    "    # 获取对应的数据\n",
    "    df_raw = pd.DataFrame(factors_raw_list[internal_name])\n",
    "    df_proc = pd.DataFrame(factors_proc_list[internal_name])\n",
    "    \n",
    "    # 强制设置索引为日期对象\n",
    "    df_raw.index = pd.to_datetime(test_months)\n",
    "    df_proc.index = pd.to_datetime(test_months)\n",
    "    \n",
    "    # 获取输出用的文件名标识\n",
    "    output_name = name_mapping.get(internal_name, internal_name)\n",
    "    \n",
    "    # 按照作业要求的目录结构命名文件\n",
    "    # 例如：factor_std_FF3_1m_raw.csv\n",
    "    df_raw.to_csv(os.path.join(OUTPUT_PATH, f'factor_{output_name}_raw.csv'))\n",
    "    df_proc.to_csv(os.path.join(OUTPUT_PATH, f'factor_{output_name}_processed.csv'))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. 因子检验\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Running Factor Tests...\")\n",
    "for internal_name in target_factors:\n",
    "    df_proc = pd.DataFrame(factors_proc_list[internal_name])\n",
    "    df_proc.index = pd.to_datetime(test_months)\n",
    "    \n",
    "    # 获取输出用的文件名标识\n",
    "    output_name = name_mapping.get(internal_name, internal_name)\n",
    "    \n",
    "    # 调用检验函数时，传入 output_name\n",
    "    run_factor_test(output_name, df_proc, close_adj, test_months, OUTPUT_PATH)\n",
    "\n",
    "print(\"All Done! Results saved to:\", OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "or",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
